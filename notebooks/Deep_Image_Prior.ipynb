{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOCftUbHzTAX",
        "outputId": "34d4e083-6adb-469b-e131-2825639c0468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GImK1ZsZvuTn"
      },
      "outputs": [],
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import cv2\n",
        "import h5py\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.layers import (\n",
        "    BatchNormalization,\n",
        "    Conv2D,\n",
        "    Input,\n",
        "    Lambda,\n",
        "    LeakyReLU,\n",
        "    UpSampling2D,\n",
        "    concatenate,\n",
        "    Layer,\n",
        "    InputSpec\n",
        ")\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import numpy.typing as npt\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import plot_model\n",
        "from skimage.exposure import rescale_intensity\n",
        "\n",
        "import tensorflow as tf\n",
        "# from keras.engine import Layer\n",
        "# from keras.engine import InputSpec\n",
        "\n",
        "# https://stackoverflow.com/questions/50677544/reflection-padding-conv2d\n",
        "class ReflectionPadding2D(Layer):\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        self.input_spec = [InputSpec(ndim=4)]\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def get_output_shape_for(self, s):\n",
        "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
        "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        w_pad,h_pad = self.padding\n",
        "        return tf.pad(x, [[0, 0], [0, w_pad], [0, h_pad], [0, 0] ], 'REFLECT')\n",
        "\n",
        "\n",
        "# def reflection_padding(x, padding):\n",
        "#     reflected = Lambda(lambda x: x[:, :, ::-1, :])(x)\n",
        "#     reflected = Lambda(lambda x: x[:, :, : padding[1], :])(reflected)\n",
        "#     upper_row = concatenate([x, reflected], axis=2)\n",
        "#     lower_row = Lambda(lambda x: x[:, ::-1, :, :])(upper_row)\n",
        "#     lower_row = Lambda(lambda x: x[:, : padding[0], :, :])(lower_row)\n",
        "#     padded = concatenate([upper_row, lower_row], axis=1)\n",
        "#     return padded\n",
        "\n",
        "\n",
        "def conv_bn_relu(x, size, filters, kernel_size, strides):\n",
        "    padding = [0, 0]\n",
        "    padding[0] = (int(size[0] / strides[0]) - 1) * strides[0] + kernel_size - size[0]\n",
        "    padding[1] = (int(size[1] / strides[1]) - 1) * strides[1] + kernel_size - size[1]\n",
        "    x = ReflectionPadding2D(padding=padding)(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    new_size = [int(size[0] / strides[0]), int(size[1] / strides[1])]\n",
        "    return x, new_size\n",
        "\n",
        "\n",
        "def down_sampling(x, size, filters, kernel_size):\n",
        "    new_size = [size[0], size[1]]\n",
        "    if size[0] % 2 != 0:\n",
        "        x = ReflectionPadding2D((1, 0))(x)\n",
        "        new_size[0] = size[0] + 1\n",
        "    if size[1] % 2 != 0:\n",
        "        x = ReflectionPadding2D((0, 1))(x)\n",
        "        new_size[1] = size[1] + 1\n",
        "    size = new_size\n",
        "    x, size = conv_bn_relu(x, size, filters, kernel_size, (2, 2))\n",
        "    x, size = conv_bn_relu(x, size, filters, kernel_size, (1, 1))\n",
        "    return x, size\n",
        "\n",
        "\n",
        "def upsample(x, size, inter):\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    if inter == \"bilinear\":\n",
        "        x_padded = ReflectionPadding2D((1, 1))(x)\n",
        "        x = Lambda(\n",
        "            lambda x: (\n",
        "                x[:, :-1, 1:, :]\n",
        "                + x[:, 1:, :-1, :]\n",
        "                + x[:, :-1, :-1, :]\n",
        "                + x[:, :-1, :-1, :]\n",
        "            )\n",
        "            / 4.0\n",
        "        )(x_padded)\n",
        "    return x, [size[0] * 2, size[1] * 2]\n",
        "\n",
        "\n",
        "def up_sampling(x, size, filters, kernel_size, inter):\n",
        "    x, size = upsample(x, size, inter)\n",
        "    x, size = conv_bn_relu(x, size, filters, kernel_size, (1, 1))\n",
        "    x, size = conv_bn_relu(x, size, filters, 1, (1, 1))\n",
        "    return x, size\n",
        "\n",
        "\n",
        "def skip(x, size, filters, kernel_size):\n",
        "    x, size = conv_bn_relu(x, size, filters, kernel_size, (1, 1))\n",
        "    return x, size\n",
        "\n",
        "\n",
        "def define_model(\n",
        "    num_u,\n",
        "    num_d,\n",
        "    kernel_u,\n",
        "    kernel_d,\n",
        "    num_s,\n",
        "    kernel_s,\n",
        "    height,\n",
        "    width,\n",
        "    inter,\n",
        "    lr,\n",
        "    input_channel=32,\n",
        "):\n",
        "    depth = len(num_u)\n",
        "    size = [height, width]\n",
        "\n",
        "    inputs = Input(shape=(height, width, input_channel))\n",
        "\n",
        "    x = inputs\n",
        "    down_sampled = []\n",
        "    sizes = [size]\n",
        "    for i in range(depth):\n",
        "        x, size = down_sampling(x, size, num_d[i], kernel_d[i])\n",
        "        down_sampled.append(x)\n",
        "        sizes.append(size)\n",
        "\n",
        "    for i in range(depth - 1, -1, -1):\n",
        "        if num_s[i] != 0:\n",
        "            skipped, size = skip(down_sampled[i], size, num_s[i], kernel_s[i])\n",
        "            x = concatenate([x, skipped], axis=3)\n",
        "        x, size = up_sampling(x, size, num_u[i], kernel_u[i], inter)\n",
        "\n",
        "        if sizes[i] != size:\n",
        "            x = Lambda(lambda x: x[:, : sizes[i][0], : sizes[i][1], :])(x)\n",
        "            size = sizes[i]\n",
        "\n",
        "    x = Conv2D(3, 1)(x)\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    return model\n",
        "\n",
        "def define_denoising_model(height, width):\n",
        "    num_u = [128, 128, 128, 128, 128]\n",
        "    num_d = [128, 128, 128, 128, 128]\n",
        "    kernel_u = [3, 3, 3, 3, 3]\n",
        "    kernel_d = [3, 3, 3, 3, 3]\n",
        "    num_s = [4, 4, 4, 4, 4]\n",
        "    kernel_s = [1, 1, 1, 1, 1]\n",
        "    lr = 0.01\n",
        "    inter = \"bilinear\"\n",
        "\n",
        "    model = define_model(\n",
        "        num_u, num_d, kernel_u, kernel_d, num_s, kernel_s, height, width, inter, lr\n",
        "    )\n",
        "    model.compile(loss=\"mse\", optimizer=Adam(learning_rate=lr))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def denoising(image:npt.NDArray):\n",
        "    height, width = image.shape[:2]\n",
        "    model = define_denoising_model(height, width)\n",
        "    input_noise = np.random.uniform(0, 0.1, (1, height, width, 32))\n",
        "\n",
        "    print(\"Starting training:\")\n",
        "    for i in range(1800):\n",
        "        x = input_noise + np.random.normal(0, 1 / 30.0, (height, width, 32))\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "          output = rescale_intensity(model.predict_on_batch(x)[0], out_range=\"uint8\")\n",
        "          cv2.imwrite(f\"/content/drive/MyDrive/deep image prior/img_003_SRF_2_HR_denoised - {i}.png\", output)\n",
        "\n",
        "        metrics = model.train_on_batch(\n",
        "            x=x,\n",
        "            y=image[None, :, :, :],\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        if i % 100 == 0:\n",
        "          print(\"Epoch: %d, Loss: %f\" % (i, metrics[\"loss\"]))\n",
        "\n",
        "    return rescale_intensity(model.predict(input_noise)[0], out_range=\"uint8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_denoising_model(320, 512)\n",
        "plot_model(model, to_file=\"/content/drive/MyDrive/deep image prior/model.png\", show_shapes=True, show_layer_activations=True)"
      ],
      "metadata": {
        "id": "fRWMF6sCCFwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio, mean_squared_error, structural_similarity\n",
        "from typing import Dict\n",
        "def img_compare(img1: npt.NDArray, img2: npt.NDArray) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculates and returns the MSE and SSIM similarity metrics between two images.\n",
        "\n",
        "    Args:\n",
        "        img1 (npt.NDArray): Image 1 to compare\n",
        "        img2 (npt.NDArray): Image 2 to compare\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]: MSE, SSIM, PSNR\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(img1, img2)\n",
        "    ssim = structural_similarity(\n",
        "        img1,\n",
        "        img2,\n",
        "        channel_axis=2,\n",
        "        gaussian_weights=True,\n",
        "        sigma=1.5,\n",
        "        use_sample_covariance=False,\n",
        "        multichannel=True\n",
        "    )\n",
        "    psnr = peak_signal_noise_ratio(img1, img2)\n",
        "\n",
        "    return {\n",
        "        \"mse\": mse,\n",
        "        \"ssim\": ssim,\n",
        "        \"psnr\": psnr,\n",
        "    }"
      ],
      "metadata": {
        "id": "EZdGk-lP1Oz2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Euz0YT1rvkx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416ecf8c-b376-4322-be8c-e0ad5a33c8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(320, 512, 3)\n",
            "Starting training:\n",
            "Epoch: 0, Loss: 12430.856445\n",
            "Epoch: 100, Loss: 967.370483\n",
            "Epoch: 200, Loss: 620.559937\n",
            "Epoch: 300, Loss: 478.816559\n",
            "Epoch: 400, Loss: 385.919800\n",
            "Epoch: 500, Loss: 322.532532\n",
            "Epoch: 600, Loss: 284.199493\n",
            "Epoch: 700, Loss: 245.544388\n",
            "Epoch: 800, Loss: 217.631958\n",
            "Epoch: 900, Loss: 191.074905\n",
            "Epoch: 1000, Loss: 174.652176\n",
            "Epoch: 1100, Loss: 152.921402\n",
            "Epoch: 1200, Loss: 144.790970\n",
            "Epoch: 1300, Loss: 127.774269\n",
            "Epoch: 1400, Loss: 117.783981\n",
            "Epoch: 1500, Loss: 106.582741\n",
            "Epoch: 1600, Loss: 98.969193\n",
            "Epoch: 1700, Loss: 91.347252\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Clean vs Noisy {'mse': 0.0, 'ssim': 1.0, 'psnr': inf}\n",
            "Denoised vs Noisy {'mse': 147.88871053059896, 'ssim': 0.8495263817920445, 'psnr': 26.43145338604619}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/skimage/metrics/simple_metrics.py:160: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return 10 * np.log10((data_range ** 2) / err)\n"
          ]
        }
      ],
      "source": [
        "# Image dimensions individually must be a multiple of 32, but it doesn't need to be square.\n",
        "# eg. 320 x 512 works. 330 x 512 doesn't\n",
        "# Image will be cropped to nearest multiple of 32 for each dimension\n",
        "\n",
        "original_img = cv2.imread(\"/content/drive/MyDrive/deep image prior/img_003_SRF_2_HR.png\")\n",
        "height, width = original_img.shape[:2]\n",
        "height_cropped = height - height % 32\n",
        "width_cropped = width - width % 32\n",
        "original_img = original_img[:height_cropped, :width_cropped, :]\n",
        "print(original_img.shape)\n",
        "\n",
        "noisy_img = cv2.imread(\"/content/drive/MyDrive/deep image prior/img_003_SRF_2_HR_noisy.png\")\n",
        "noisy_img = original_img[:height_cropped, :width_cropped, :]\n",
        "\n",
        "denoised_img = denoising(noisy_img)\n",
        "cv2.imwrite(\"/content/drive/MyDrive/deep image prior/img_003_SRF_2_HR_denoised.png\", denoised_img)\n",
        "\n",
        "print(\"Clean vs Noisy\", img_compare(original_img, noisy_img))\n",
        "print(\"Denoised vs Noisy\", img_compare(denoised_img, noisy_img))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}